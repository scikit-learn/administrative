\documentclass[twoside,11pt]{article} 
\usepackage{jmlr2e} 
\usepackage{hyperref}
\jmlrheading{1}{2011}{1-48}{4/00}{10/00}{Pedregosa, Varoquaux et al.}

% Short headings should be running head and authors last names

\usepackage{xcolor}
\usepackage[normalem]{ulem}

\newcommand{\GAEL}[1]{\textcolor{blue}{\uline{#1}}}
\newcommand{\FABIAN}[1]{\textcolor{red}{\uline{#1}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\ShortHeadings{scikits.learn: machine learning in Python}{Pedregosa, Varoquaux et al.}
\firstpageno{1}


\begin{document}

\title{scikits.learn: machine learning in Python}


\author{\name Fabian Pedregosa \email fabian.pedregosa@inria.fr \\
        \name Gael Varoquaux \email gael.varoquaux@normalesup.org  \\
        \name Alexandre Gramfort \email alexandre.gramfort@inria.fr \\
        \name Vincent Michel  \email vincent.michel@inria.fr \\
        \name Bertrand Thirion  \email bertrand.thirion@inria.fr \\
        \addr  Neurospin, B\^atiment 145\\
        point courier 156, CEA Saclay\\
        91191 Gif sur Yvette – FRANCE
        \AND
        \name Olivier Grisel \email olivier.grisel@ensta.fr \\
        \addr Nuxeo \\
        \\
        \AND
        \name MANY MORE
}


\editor{?}

\maketitle

\begin{abstract}
\emph{Scikits.learn} is a Python module integrating
a wide range of state-of-the-art machine learning algorithms for
medium-scale supervised and unsupervised problems. This package
focuses on bringing machine learning to non-specialists using a
general-purpose high-level language with a special care on ease of use,
documentation and consistent API.


scikits.learn is licensed under the simplified BSD license,
encouraging its use in both free and commercial settings. Soruce code
and documentation can be downloaded from
\url{http://scikit-learn.sourceforge.net}.

\end{abstract}

\keywords{Python, supervised learning, unsupervised learning}


%%  It offers a wide range of
%% methods such as Support Vector Machines, linear models (L1, L2
%% penalized), logistic regression, gaussian mixture models and more.


\section{Introduction}
In the past years the Python programming language has experienced a
huge increase as the language of choice for scientific computing. Its
high level, interactive nature and its maturing ecosystem of
scientific libraries (numpy, scipy, matplotlib) [Mars 2011 CiSE]
make it a very appealing choice for both research and industry.


%% We have also found it to be a convenient vector of communication with
%% the non-specialist. Users can use an interactive, easy-to-learn,
%% general-purpose language and have access to state-of-the-art
%% scientific software.

%% In a context such as
%% machine learning where state-of-the art methods are routinely used by
%% non-specialist.

This motivated us to develop a library with the goal of providing
efficient implementations of state-of-the-art machine learning
algorithms for the Python language. The resulting project, called
scikits.learn aims to provide a reference implementation of some of
the best known machine learning algorithms, while maintaining an
easy-to-use interface tightly integrated in the Python language. The
package is mostly coded in Python, although some algorithms are coded
in Cython or C/C++ language for efficiency. Also, because of their
high quality and compatible license, we incorporate the C/C++
libraries LibSVM and LibLinear and provide high-quality, low-overhead
bindings for these.


The package has only numpy and scipy as strict dependences, which ensure
it's availability in a rich set of platforms including
Windows and any POSIX platforms. Furthermore, it is distributed as part of
major open source distributions such as Ubuntu, Debian, Mandriva, NetBSD
or Macports and in commercial distributions such as ``Enthought Python
Distribution'' thanks to its very liberal BSD license.



\section{Underlying technologies}

%% An important aspect in the design of scikits.learn is to make
%% extensive use of python scientific libraries such as numpy and
%% scipy. This allows for maximum code reuse while reducing deployment
%% costs.

scikits.learn builds upon a powerful stack of existing libraries.

\paragraph{Numpy}

Numpy provides the base data structure for representing
information. This choice strives for easy of use by using plain numpy
arrays instead of specialized data structures and limiting framework
code. Our objects work directly with NumPy arrays, providing a
flexible way to communicate with other packages.

\paragraph{Scipy} 

Scipy provides us with the efficient algorithms for linear algebra,
sparse matrix structure, special functions and basic statistical
functions.

\paragraph{Cython}

The purpose of Cython is twofold. First, it allows to reach the
performance of compiled languages as C while retaining a Python-like
syntax. Second, Cython allows to easily access third-party libraries,
effectively eliminating most of the boilerplate code associated with
Python/C extensions.

\paragraph{Matplotlib}

Optional but highly recommended, visualization and examples.

%% what sets us apart from many other machine learning toolboxes, is
%% that ...


\section {Project vision}


The library is structured in submodules, each of which covers a family
of related algorithms. This way, the svm module support vector
machine-related algorithms of classification (SVC), regression (SVR)
and unsupervised learning (OneClassSVM).


\paragraph{Code by interface, not by inheritance}

Inheritance is not enforced at any stage. However, we adopt some
conventions that make the API easier to learn. Estimators are object
that implements that implement a `fit` and `predict` method,
independently of its class hierarchy. Examples of estimators include
Support Vector Classification, k-Nearest Neighbors and the Lasso.

Some more specialized objects might also implement a score function
for testing the accuracy of an estimator.

Some classes of unsupervised also implement a transform for [...].


%% However, some properties in the algorithms (warm restarts, path
%% solutions, etc.) can, and should be used be used to speed up the
%% process. To allow this The methods are model-dependent and are
%% implemented in classes that append ``CV'', for cross-validation, to
%% the model name (Lasso and LassoCV, etc.)


\paragraph{Community-driven development}

We base our development on collaborative tools such as git, github and
public mailing lists. External contributions are welcomed and
encouraged via developer manual and API guidelines. Quality of
existing code is ensured [ha!] with unitary tests and regularly
checked with tools such as pep8, pyflakes, coverage.

%% Special care has been taken to encourage external contributions. First
%% of, every significant function is documented and tested.  Ohloh, the
%% open source directory, describes the project as ``Well-commented
%% source code'' and ``Very large, active development team''.


%% We have succesfully used this software to real-world problems. Some
%% applications can be seen in the online gallery, featuring more than 60
%% examples.

\paragraph{Documentation}

We believe that documentation is a key component of a software
distribution, and as such scikits.learn includes a ~300 page user
guide with narrative documentation, class reference, tutorial,
installation instructions as well as a collection of more than 60
examples, some of them featuring real-world applications of the
library.


\section{Computational efficiency tradeoffs}


Special care has been take on algorithmic efficiency, producing
algorithms that are ofter faster than the ones found in compiled
libraries.


\begin{center}
%% \caption{Overview of existing machine learning libraries}

% it would be nicer with checkbox images

\begin{tabular}{l c c c c c c}
\hline\hline %inserts double horizontal lines 
 & scikits.learn & mlpy & pybrain & pymvpa &  mdp & shogun \\ [0.5ex]
\hline
Support Vector Machines & 6.39 & 9.55 & - & 10.34 & 20.62 & 15.79 \\
Lasso LARS & 1.45 & 168.25   & -       &  64.89     & -    & - \\
Elastic Net & 0.61 & 59.32 & -  &  ??  & -  & - \\
Gaussian Mixture Models  & 0.0 & 0.0   & 0.0       &  0.0     & 0.0    & - \\
k-Nearest Neighbors & 1.38 & 0.30  & - &  0.75 & 59.62    & 0.73 \\
Indep. Component Analysis & 0.0 & 0.0  & 0.0  & 0.0  & 0.0  & - \\
ANN  & - & 0.0  & 0.0  & 0.0  & 0.0  & - \\
License &  BSD & GPL & BSD  &  BSD  & BSD  & GPL \\
\hline
\end{tabular}

\end{center}

%% WHAT TO DO WHITH THE ALGORITHMS THAT ARE IMPLEMENTED IN MDP VIA
%% SCIKIT-LEARN ??

%% Least Angle Regression is implemented in pure Python and achieve 10x
%% to 2x gain in performance over the reference implementation, the R
%% package LARS, by smarter updates of coefficients [rephrase].

%% The elasticnet algorithm, by coordinate descent, coded in Cython
%% achieves the same order of performance as the highly optimized Fortran
%% version elasticnet.

%% Also, fast k-nearest neighbors is achieved by constructing a binary
%% tree of the samples similar to the one found in the kd-tree structure.

\section{Code design}


\paragraph {Model selection}

Model selection is the problem of finding optimal parameters for a
model with the data at hand [...]. Usually, this process is carried
out by measuring the performance of the different classifiers over all
possible parameters.

To ease this repetitive task, scikits.learn proposes some convenience
objects. GridSearchCV is takes as input a classifier and a list of
parameters and stores the best one. This works because all estimators
in scikits.learn implement functions .\emph{fit}, \emph{predict} and
possibly \emph{score} so GridSearchCV is able to use classifiers as
black boxes.

For convenience, GridSearchCV is also a classifier (implements fit and
predict), thus can be used transparently as any other classifier.

However, some models allow for further optimizations. For example,
LARS provides the full path, coordinate descent methods allow for warm
restarts, etc.



\section{Conclusions}

Today the project already contains more than 40 algorithms ranging
from supervised to unsupervised learning, providing an unequal
framework for easily comparison of different methods on a given
application.



While the choice of Python ensoures code reuse in the package, it also
binds us to this language and limits its use outside the Python
language.

This effectively rules out code sharing with other major scientific
platforms, such as MATLAB©, Octave, and R.



\section{References}

ME:

\includegraphics{images/parafaber.jpg}

\end{document}
