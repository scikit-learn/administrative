\documentclass[twoside,11pt]{article} 
\usepackage{jmlr2e} 
\usepackage{hyperref}
\jmlrheading{1}{2011}{1-48}{4/00}{10/00}{Pedregosa, Varoquaux et al.}

% Short headings should be running head and authors last names

\usepackage{xcolor}
\usepackage[normalem]{ulem}

\newcommand{\GAEL}[1]{\textcolor{blue}{\uline{#1}}}
\newcommand{\FABIAN}[1]{\textcolor{red}{\uline{#1}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\ShortHeadings{scikits.learn: machine learning in Python}{Pedregosa, Varoquaux et al.}
\firstpageno{1}


\begin{document}

\title{scikits.learn: machine learning in Python}


\author{\name Fabian Pedregosa \email fabian.pedregosa@inria.fr \\
        \name Gael Varoquaux \email gael.varoquaux@normalesup.org  \\
        \name Alexandre Gramfort \email alexandre.gramfort@inria.fr \\
        \name Vincent Michel  \email vincent.michel@inria.fr \\
        \name Bertrand Thirion  \email bertrand.thirion@inria.fr \\
        \addr  Neurospin, B\^atiment 145\\
        point courier 156, CEA Saclay\\
        91191 Gif sur Yvette – FRANCE
        \AND
        \name Olivier Grisel \email olivier.grisel@ensta.fr \\
        \addr Nuxeo \\
        \\
        \AND
        \name MANY MORE
}


\editor{?}

\maketitle

\begin{abstract}
\emph{Scikits.learn} is a Python module integrating
a wide range of state-of-the-art machine learning algorithms for
medium-scale supervised and unsupervised problems. This package
focuses on bringing machine learning to non-specialists using a
general-purpose high-level language with a special care on ease of use,
documentation and consistent API.


scikits.learn is licensed under the simplified BSD license,
encouraging its use in both free and commercial settings. Soruce code
and documentation can be downloaded from
\url{http://scikit-learn.sourceforge.net}.

\end{abstract}

\keywords{Python, supervised learning, unsupervised learning}


%%  It offers a wide range of
%% methods such as Support Vector Machines, linear models (L1, L2
%% penalized), logistic regression, gaussian mixture models and more.


\section{Introduction}
In the past years the Python programming language has experienced a
huge increase as the language of choice for scientific computing. Its
high level, interactive nature and its maturing ecosystem of
scientific libraries (numpy, scipy, matplotlib) [Mars 2011 CiSE]
make it a very appealing choice for both research and industry.


%% We have also found it to be a convenient vector of communication with
%% the non-specialist. Users can use an interactive, easy-to-learn,
%% general-purpose language and have access to state-of-the-art
%% scientific software.

%% In a context such as
%% machine learning where state-of-the art methods are routinely used by
%% non-specialist.

This motivated us to develop a library with the goal of providing
efficient implementations of state-of-the-art machine learning
algorithms for the Python language. The resulting project, called
scikits.learn aims to provide a reference implementation of some of
the best known machine learning algorithms, while maintaining an
easy-to-use interface that integrates nicely into the Python language
\FABIAN{A better way to say this?}.

The package has only numpy and scipy as strict dependences, which ensure
it's availability in a rich set of platforms. scikits.learn runs on
Windows and POSIX platforms. Furthermore, it is distributed as part of
major open source distributions such as Ubuntu, Debian, Mandriva, NetBSD
or Macports and in commercial distributions such as ``Enthought Python
Distribution'' thanks to its very liberal BSD license.



\section{Underlying technologies}

%% Frankly, we just do the same thing as everybody else. Maybe a bit
%% better.

%% An important aspect in the design of scikits.learn is to make
%% extensive use of python scientific libraries such as numpy and
%% scipy. This allows for maximum code reuse while reducing deployment
%% costs.


scikits.learn builds upon a powerful stack of existing libraries.

\paragraph{Numpy}

Numpy provides the base data structure for representing
information. This choice strives for easy of use by using plain numpy
arrays instead of specialized data structures and limiting framework
code.

\paragraph{Scipy} \GAEL{Survey what part of scipy we use: linear algebra,
graphs (sparse matrices), basics statistical tools. Anything else? Grep
will tell us}

TODO.

\paragraph{Cython}

The purpose of Cython is twofold. First, it allows to reach the
performance of compiled languages as C for algorithms that cannot be
coded efficiently using Numpy/Scipy while retaining a Python-like
syntax and garbage collection. Second, Cython allows to easily access
third-party libraries, effectively eliminating most of the boilerplate
code associated with Python/C extensions.

%% what sets us apart from many other machine learning toolboxes, is
%% that ...


\section {Project vision}

In order to maintain the source code comprehensible and easily
extensible, as much as possible is coded in the Python language. This
forces us to take special care on algorithmic efficiency, and as such
we have produced algorithms that are often faster than the ones found
in compiled libraries. \FABIAN{Need an example to corroborate this !!!!}

However, because of their high quality and compatible license, we also
incorporate C/C++ libraries libsvm and liblinear. These libraries have
been carefully binded using Cython, eliminating most of the C/Python
communication overhead present in other bindings. These bindings are
also unique in the sense that they are capapable of working natively
(without conversion) with both dense and sparse arrays.

[BENCH IMAGE SVM]

We firmly believe that documentation is a key component of a software
distribution, and as such scikits.learn includes a ~300 page user
guide with narrative documentation, class reference, tutorial,
installation instructions as well as a collection of more than 60
examples, some of them featuring real-world applications of the
library.

[TEST COVERAGE]


\paragraph{Code by interface, not by inheritance}
%

We adopt simple conventions and limit the number of methods an object
has to implement. 

Inheritance is not enforced, and any classifier implementing these
methods is able to plug in the scikits.learn framework.

%% In its simples form, a classifier is an object that
%% implements a \emph{fit} and \emph{predict} method. 

%% More spcialized classifiers might implement other methods as
%% well. Filters are objects that implement a \emph{transform} method,
%% and serve for feature selection.

\GAEL{The word filter is often used in ML for specific kind of
transformations. We should refrain from using it. In the scikit we now
call these objects 'Transforms'. }

\GAEL{Speak here about API for unsupervised problems: score, transform and
predict can be useful to give an application-centric meaning to
unsupervised models.}


A unified approach for model selection is needed to tune parameters in
a method-independent manner. In scikits.learn we solved this problem
is with an object that takes as input a classifier, and a set of
possible parameters.


This way we can abstract from the method
and provide a generalized interface for model selection.


However, in practice method-specific considerations must be taken for
efficiency.


Our solution is based on one side on having an object GridSearch that
[...] 

However, this does not allow the use of model-specific information to
cross validate. To help this, some algorithms have a cross-val
counterpart.

%% However, some properties in the algorithms (warm restarts, path
%% solutions, etc.) can, and should be used be used to speed up the
%% process. To allow this The methods are model-dependent and are
%% implemented in classes that append ``CV'', for cross-validation, to
%% the model name (Lasso and LassoCV, etc.)


\paragraph{Community-driven development}

To ensure the project continuity ...

Special care has been taken to encourage external contributions. First
of, every significant function is documented and tested.  Ohloh, the
open source directory, describes the project as ``Well-commented
source code'' and ``Very large, active development team''.

\GAEL{Speak of coding standards, and testing} 

Also, a precise instructions on how to contribute as well as coding
guidelines make contributing code easy and efficient process. 28
developers contributed code over the last twelve months.

We have succesfully used this software to real-world problems. Some
applications can be seen in the online gallery, featuring more than 60
examples.


\section{Computational efficiency tradeoffs}


\begin{center}
%% \caption{Overview of existing machine learning libraries}

% it would be nicer with checkbox images

\begin{tabular}{l c c c c c c}
\hline\hline %inserts double horizontal lines 
 & scikits.learn & mlpy & pybrain & pymvpa &  mdp & shogun \\ [0.5ex]
\hline
Support Vector Machines        & 0.0 & 0.0   & 0.0       &  0.0     & 0.0    & 0.0 \\
Elastic Net & 0.0 & 0.0   & 0.0       &  0.0     & 0.0    & - \\
Gaussian Mixture Models  & 0.0 & 0.0   & 0.0       &  0.0     & 0.0    & - \\
k-Nearest Neighbors & 0.0 & 0.0   & 0.0       &  0.0     & 0.0    & - \\
Indep. Component Analysis & 0.0 & 0.0  & 0.0  & 0.0  & 0.0  & - \\
ANN  & - & 0.0  & 0.0  & 0.0  & 0.0  & - \\
Usable in commercial code &  0.0 & -   & 0.0       &  0.0     & 0.0    & - \\
\hline
\end{tabular}

\end{center}

|| BENCKMARK IMAGE ||

Special care has been take on algorithmic efficiency, producing
algorithms that are ofter faster than the ones found in compiled
libraries.

Least Angle Regression is implemented in pure Python and achieve 10x
to 2x gain in performance over the reference implementation, the R
package LARS, by smarter updates of coefficients [rephrase].


The elasticnet algorithm, by coordinate descent, coded in Cython
achieves the same order of performance as the highly optimized Fortran
version elasticnet.

Also, fast KNN in high-dimensional spaces is achieved using the
BallTree algorithm (C++).

|| BENCH ||

\section{Code design}




\section{Conclusions}

Today the project already contains more than 40 algorithms ranging
from supervised to unsupervised learning, providing an unequal
framework for easily comparison of different methods on a given
application.



While the choice of Python ensoures code reuse in the package, it also
binds us to this language and limits its use outside the Python
language.

This effectively rules out code sharing with other major scientific
platforms, such as MATLAB©, Octave, and R.



\section{References}



\end{document}
