# September 28th 2020 -- Scikit-learn dev meeting

### Need decision

- (Nicolas) `check_estimator(strict_mode=False)`: [what do we include in the non-strict mode?](https://github.com/scikit-learn/scikit-learn/issues/13969#issuecomment-693715975)

  - The "strict mode" should determine whether we *just* check for API compatibility, or if we  enforce some more advanced checks like error message validation, or discrimination power of a classifier.
    Anything that's not directly related to API should be part of the "strict" mode.
  - API checks include compatibility in pipeline, gridsearch and scorers.
  - The parameter name should change from `strict_mode` to e.g. `api_only`
  - Some additional parameters may be added in the future but no need to overcomplicate things for now.
    Whatever we may add in the future, the API checking should be the bare minimum to pass the check suite and cannot be disabled. 
 
- (Andy) [array_out](https://github.com/scikit-learn/scikit-learn/pull/16772): Global option (tricky for downstream), keyword argument to transform or new method.
    - having a local way, like a kwarg to `transform` avoids complications with dependencies, on the other hand it adds a bit of verbosity
    - for now: let's have the parameter array_out='ndarray' independent of input type, with possiblity to evolve.
    - in the future we may add a global option to change the default.
    - Does this need a SLEP? There is a [SLEP014](https://github.com/scikit-learn/enhancement_proposals/pull/37) already, it will be modified accordingly then voted.
    - (Alex) in pipelines every step should have out_type and break if out_type is not 'ndarray'.
    - for now feature names don't need pandas dataframe, user should input feature names and they will be outputted with something like
      `pipeline.get_output_names(X.columns)`, either `get_feature_names_out()` or `get_output feature_names()`
    - Thomas will make [#18444](https://github.com/scikit-learn/scikit-learn/pull/18444) easier to review.

### Need attention (review)

- (Thomas) Missing value support for `OneHotEncoder` [#17317](https://github.com/scikit-learn/scikit-learn/pull/17317)
    - needs another review, Joel has looked at it
- (Andy) [get_output_names/get_feature_names](https://github.com/scikit-learn/scikit-learn/pull/18444) for all estimators
    - Thomas's solution deprecates this

### General topics

- (Olivier) Who is interested in changelog automation? Need to review how other projects do it.
    - (Thomas) As a reference numpy does this by having PRs write a separate file and then [auto generating the changelog when releasing](https://github.com/numpy/numpy/pull/16280).
    - Goal: To avoid merge conflicts on the changelog and ensure master and dev branch are up to date
    - Merge commit will contain PR number, each PR will have a single text file with PR-specific whatsnew that will get merged automatically into one whatsnew.
    - A first step is to figure out what others are doing

- (Andy) Moving meeting / rolling meetings (aka I move to CA)
    - should find a rolling style or at least two alternative times
    - we'll do a doodle
    - also helpful: https://www.timeanddate.com/worldclock/meetingtime.html?month=10&day=26&year=2020&p1=179&p2=240&p3=195&p4=224&iv=0

- (Olivier) Python 3.9 needs us to make a new release of loky / joblib.
    - release binaries of sklearn for an already released version of sklearn for Py3.9
    - could limit the uppper python version supported so that people don't accidentally install sklearn on an unsupported python release

- Sprints: we seem to be a bit tired and need to recover

- (Alex) Deprecations of normalize parameter are stuck because there is no sample weights in pipeline: the user can specify to which steps weights should be
    passed for each step.
    - Discussion shifted to some issue with the current design (i.e. explicit routing of SWs in pipeline): if the pipeline changes, the routing also needs to
      change. Passing step names instead of relying on `make_pipeline` slightly helps but code still breaks if the nesting/structure of the pipeline estimator
      changes.
    - passing pipe.fit(X, y, sample_weights=...) isn't currently supported because we don't know what to do if one step doesn't support SWs: raise an error,
      or just ignore weights for that step. It's even more tricky since for some tranformers like Normalizer, SWs don't  make sense anyway.
      Note that we will need to decide on  this if we wish to determine SW support via an estimator tag. Currently SW support is determined by inspecting the `fit` method's parameters.

- Reminder: [label for backward compatibility breaking change](https://github.com/scikit-learn/scikit-learn/issues?q=is%3Aopen+is%3Aissue+label%3A%22Breaking+Change%22)
