 # Scikit-learn Monthly Developer

## June 30, 2025
## Time: 4pm CEST

### Updates

### Topics

- [name=Lo√Øc] (not present) Require 2FA at the scikit-learn organization level? There was consensus about this in January 2022 in the internal mailing list but we never required it (here is the [settings page](https://github.com/organizations/scikit-learn/settings/security)). Everyone in the org already uses 2FA except a few bots and only `sklearn-ci` is still used I think (to push to the scikit-learn.github.io website) and would need 2FA enabled. See this [page](https://github.com/orgs/scikit-learn/people?query=two-factor%3Adisabled) for the org members without 2FA. Requiring "secure" 2FA (i.e. that everyone in the org disables 2FA via text message in their profile [settings](https://github.com/settings/security)) is probably best left for later, one step at a time...
    - Olivier: We can probably configure a 2FA for `sklearn-ci` via the shared 1password.com.
    - Q: do we want to require MFA for Discord server?
- [name=Olivier] 1.7.1 release planning? Any big regression to mandate a fast bugfix release?
    - Make a softer deprecation for a private dev tool: https://github.com/scikit-learn/scikit-learn/pull/31500
    - HTML representation was failing with non-default parameter if it was a sequence: https://github.com/scikit-learn/scikit-learn/pull/31528
    - [FIX use pyarrow types in pyarrow.filter() for older pyarrow versions](https://github.com/scikit-learn/scikit-learn/pull/31605)?
    - milestone https://github.com/scikit-learn/scikit-learn/milestone/67

- [name=Stefanie] increasing amount of AI generated PRs, see issue [AI tools like Copilot Coding Agent don't know about / don't respect our Automated Contributions Policy](https://github.com/scikit-learn/scikit-learn/issues/31679)
    - First time: remind and link to the section related to automated in the doc. Then block if repeated offense.
    - Update the CONTRIBUTING.md file to hopefully make the LLM themselves refuse to open such PRs:
        - https://github.com/scikit-learn/scikit-learn/pull/31643
    - Please do not copy and paste the output of an LLM in the github discussion when addressing reviewers comments.
    - Problem is people copy and pasting with little efforts in trying to understand what they paste in the discussion (or the diff in the code).
    - Extend https://scikit-learn.org/dev/developers/contributing.html#automated-contributions-policy to include "take part in discussion" (not just opening new Issues or PRs)

- [name=Sylvain] (I might not be available today - if not, looking forward to reading the minutes on hackmd) follow-up on the topic of randomized svd/eigen solvers.
    - I opened an issue [on SciPy](https://github.com/scipy/scipy/issues/23145) as discussed. First feedback confirmed that the topic had already been identified as interesting in [Scientific Python discussions](https://discuss.scientific-python.org/t/add-lsrn-solver/1888/1).
        - Olivier: +1 for upstreaming to scipy if the scipy maintainers agree which seems to be the case based on the discussion.
    - On [PR#31247](https://github.com/scikit-learn/scikit-learn/pull/31247) (Isomap), since the students have ended their project, it seem that there was no response to Olivier's last comment. I might have to have a look in August to unlock this.
        - Olivier: alright, no hurry on my side ;)


### Need attention/decision

- [name=Olivier] inclusion criterion for:
    - PR: https://github.com/scikit-learn/scikit-learn/pull/31279
    - paper: https://arxiv.org/abs/1903.05179
    - published in ACM TKDD 2021
    - google scholar: 117 citations
    - pros:
        - fixes bias problems observed with popular MDI `feature_importances_` computed on the training set only and currently implemented in scikit-learn
        - uses the out-of-sample data points of the random forest to debias traditional MDI
        - compares favorably to another alternative to remove the bias
            - https://proceedings.neurips.cc/paper_files/paper/2019/file/702cafa3bb4c9c86e4a3b6834b45aedd-Paper.pdf
            - BTW: we found out that the NeurIPS paper has a bug in the code they provide (it does not exactly match the code of the paper and the formula of the NeurIPS paper would translate to code very similar to the ACM TKDD paper if implemented correctly)
        - empirically decomposes the Brier score / MSE loss into additive per-feature contributions similarly to [SAGE](https://github.com/iancovert/sage)
        - much faster to compute than running SAGE on a random forest
        - much better sample complexity than SAGE (or traditional MDI)
    - cons:
        - just below our inclusion criterion (200 citations)
        - only exist for Gini / MSE losses (failed to find a way to adaptd it to Shannon entropy criterion).
    - Jeremie: not introducing a new estimator. A bit like an a bugfix or an enhancement:
        - rename the old attribute to `biased_feature_importance_`.
    - Christian: update the User Guide to warn users to not interpret outputs of model inspection tools as a causal effects and point them to libraries or tools dedicated to causal effect estimation.

### Action items


### Archived meeting notes:

- https://github.com/scikit-learn/administrative/tree/master/monthly_meetings


### Next meeting

Automatically configured as a recurring event on the shared calendar:

- https://blog.scikit-learn.org/calendar/
