# *June 28th 2021*

When you add an entry, please add you  name next to it.

### Need decision

- Olivier: [Issue #20111](https://github.com/scikit-learn/scikit-learn/issues/20111) change the default value for RandomForestRegressor's `max_features` from `None` (no feature subsampling) to `sqrt` (subsampling uniformly `sqrt(n_features)`). [Benchmarks here](https://github.com/scikit-learn/scikit-learn/issues/20111#issuecomment-868767783)
    - Justification is historical from Breiman
    - The benchmarks show no real difference in performance
    - One benefit would be speed
    - Another benefit would be reducing the user surprise
    - **Documentation could be improved**
        - Suggestion (Andy): Rename 'auto' in a more explicit name (eg: 'n_features')
            - Users that explicitly specify "n_features" get no warning
            - Users that don't set `n_features` get no warning and the behaviour doesn't change
            - Users that explicitly specify "auto" get a deprecation warning
            - This should be done for Regressors, Classifiers, Forest and DecisionTree estimators.
- Olivier: [Issue #8215](https://github.com/scikit-learn/scikit-learn/issues/8215) Brownout strategy to remove the `sklearn` alias package from PyPI.org
    - **Proposal**: slowly raising error from time to time so that people become aware of the issue
        - eg: scheduled window of time where there is an error and warning in advance
        

### Need attention (reviews)

- Olivier: [Issue #20319](https://github.com/scikit-learn/scikit-learn/issues/20319) RFC: opinions/feedback on experience with critical difference diagrams to compare the relative performance of scikit-learn models?
    - The diagram is only a small aspect of critical thinking in terms of comparing models
    - Ideally, a good example / documentation would get users to think about the valid tests:
        - Across multiple datasets https://www.jmlr.org//papers/v7/demsar06a.html 
        - Null-hypothesis testing (corrected resampled t-test, in table 1) https://link.springer.com/article/10.1023/A:1024068626366
        - Accounting for multiple sources of variances (eg init) https://proceedings.mlsys.org/paper/2021/hash/cfecdb276f634854f3ef915e2e980c31-Abstract.html a superiority test, and not a null-hypothesis test
- Guillaume: `n_features_in_` is done ([Issue #19333](https://github.com/scikit-learn/scikit-learn/issues/19333)). 
    - Next steps in order of priority:
        - feature names consistency checks [PR #18010](https://github.com/scikit-learn/scikit-learn/pull/18010) - Thomas to update PR, Olivier/Guillaume and Andy to follow up.
        - output feature names for transformers [SLEP015](https://github.com/scikit-learn/enhancement_proposals/pull/48) [PR #18444](https://github.com/scikit-learn/scikit-learn/pull/18444)
        - pandas in/pandas out [Issue #20258](https://github.com/scikit-learn/scikit-learn/issues/20258)
    - **Comment** We can move forward in terms of capturing the feature names in the input 
        - get_features_name_out for transformers as a temporary way forward
        - this enables to move forward in the next steps
    - TODO: update the SLEP for `n_features_in_` to mention the issue number (#19333) and the fact that is implemented as part of scikit-learn 1.0.
 - [PR #19088](https://github.com/scikit-learn/scikit-learn/pull/19088): Common Private Loss Module
    > [name=Julien] This PR is from Christian and is waiting for more reviewers. 
    - Would the behaviors for loss functions change with this new module?
    - The test suite is more complete that the current tests'.
    - Some discussion regarding tread-off between design and performance: https://github.com/scikit-learn/scikit-learn/pull/19088#discussion_r634189970
- Adrin/Guillaume: unbiased `feature_importances_` in random forest [ISSUE #20059](https://github.com/scikit-learn/scikit-learn/issues/20059) and [PR #18603](https://github.com/scikit-learn/scikit-learn/pull/18603)
     - proposal to deprecate `feature_importances_` and have `get_feature_importances(test_data)`
     - problem is that it breaks feature selection objects
- Christian: [PR #17443](https://github.com/scikit-learn/scikit-learn/pull/17443) ENH Add CalibrationDisplay plotting class
    - Guillaume will have a look

### General topics

- Olivier: `black`: feedback from the code formatter switch? Things to adjust?
    - Improve multi-line string reformatting: [#20412](https://github.com/scikit-learn/scikit-learn/pull/20412)
    - Sleep on it and suggest a vote for 79 chars, with PR with the diff

### Next meeting date and chair person
- date: 26 july time to be decided
- chair: Thomas does the doodle & Guillaume does the invitation

Previous meeting notes:
https://github.com/scikit-learn/administrative/tree/master/meeting_notes


### Action items

- Documentation update for Random Forest, deprecate `n_features='auto'` and use explcit names, i.e. `'sqrt'`
- Moving forward with Brown out for `sklearn`
- Feature names consistency checks
- Update the [SLEP010](https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep010/proposal.html) for `n_features_in_`
